
  0%|                                                                              | 0/40 [00:00<?, ?it/s]
35.84300535917282

  2%|█▎                                                   | 1/40 [00:02<01:55,  2.95s/it, loss_test=0.919]
64.33819285035133
136
Epoch: 00, Training Loss: 0.4731, Test Loss: 0.9191
12.995117098093033

  5%|██▋                                                  | 2/40 [00:05<01:47,  2.83s/it, loss_test=0.333]
48.10894799232483
136
Epoch: 01, Training Loss: 0.3537, Test Loss: 0.3332
12.724430710077286
39
46.64358341693878
136

  8%|███▉                                                 | 3/40 [00:08<01:44,  2.82s/it, loss_test=0.326]
12.69895651936531

 10%|█████▎                                               | 4/40 [00:11<01:39,  2.77s/it, loss_test=0.326]
46.25323197245598
136
Epoch: 03, Training Loss: 0.3401, Test Loss: 0.3256
12.652269870042801
39
45.90273877978325
136
Epoch: 04, Training Loss: 0.3375, Test Loss: 0.3244
12.630118697881699


 15%|███████▉                                             | 6/40 [00:16<01:33,  2.75s/it, loss_test=0.324]
45.26766312122345
136
Epoch: 05, Training Loss: 0.3329, Test Loss: 0.3238
12.42243281006813

 18%|█████████▎                                           | 7/40 [00:19<01:29,  2.71s/it, loss_test=0.319]
44.54507231712341
136
Epoch: 06, Training Loss: 0.3275, Test Loss: 0.3185
12.332911491394043

 20%|██████████▌                                          | 8/40 [00:22<01:27,  2.72s/it, loss_test=0.316]
44.055604696273804
136
Epoch: 07, Training Loss: 0.3239, Test Loss: 0.3162
12.266914635896683

 22%|███████████▉                                         | 9/40 [00:24<01:23,  2.68s/it, loss_test=0.315]
43.915517419576645
136
Epoch: 08, Training Loss: 0.3229, Test Loss: 0.3145
12.449881821870804

 25%|█████████████                                       | 10/40 [00:27<01:20,  2.67s/it, loss_test=0.319]
43.910131335258484
136
Epoch: 09, Training Loss: 0.3229, Test Loss: 0.3192
12.332480758428574

 25%|█████████████                                       | 10/40 [00:29<01:20,  2.67s/it, loss_test=0.316]
43.63622206449509
136

 28%|██████████████▎                                     | 11/40 [00:29<01:17,  2.66s/it, loss_test=0.316]
12.241968393325806
39
43.84393659234047
136

 28%|██████████████▎                                     | 11/40 [00:32<01:17,  2.66s/it, loss_test=0.314]
12.305373102426529

 32%|████████████████▉                                   | 13/40 [00:35<01:13,  2.71s/it, loss_test=0.316]
43.720691442489624
136
Epoch: 12, Training Loss: 0.3215, Test Loss: 0.3155
12.177755177021027

 35%|██████████████████▏                                 | 14/40 [00:38<01:09,  2.69s/it, loss_test=0.312]
43.43181973695755
136
Epoch: 13, Training Loss: 0.3194, Test Loss: 0.3123
12.168780267238617

 38%|███████████████████▌                                | 15/40 [00:40<01:07,  2.69s/it, loss_test=0.312]
43.44611209630966
136
Epoch: 14, Training Loss: 0.3195, Test Loss: 0.3120
12.558797150850296

 40%|████████████████████▊                               | 16/40 [00:43<01:04,  2.69s/it, loss_test=0.322]
43.53240242600441
136
Epoch: 15, Training Loss: 0.3201, Test Loss: 0.3220
12.77660745382309

 42%|██████████████████████                              | 17/40 [00:46<01:01,  2.68s/it, loss_test=0.328]
43.5378959774971
136
Epoch: 16, Training Loss: 0.3201, Test Loss: 0.3276
12.394372135400772

 45%|███████████████████████▍                            | 18/40 [00:48<00:59,  2.70s/it, loss_test=0.318]
43.48935154080391
136
Epoch: 17, Training Loss: 0.3198, Test Loss: 0.3178
12.161570638418198

 48%|████████████████████████▋                           | 19/40 [00:51<00:56,  2.67s/it, loss_test=0.312]
43.41710954904556
136
Epoch: 18, Training Loss: 0.3192, Test Loss: 0.3118
12.342639684677124

 50%|██████████████████████████                          | 20/40 [00:54<00:53,  2.69s/it, loss_test=0.316]
43.36198577284813
136
Epoch: 19, Training Loss: 0.3188, Test Loss: 0.3165
12.184846311807632

 52%|███████████████████████████▎                        | 21/40 [00:56<00:51,  2.70s/it, loss_test=0.312]
43.29425260424614
136
Epoch: 20, Training Loss: 0.3183, Test Loss: 0.3124
12.344437450170517

 55%|████████████████████████████▌                       | 22/40 [00:59<00:48,  2.72s/it, loss_test=0.317]
43.2550932765007
136
Epoch: 21, Training Loss: 0.3181, Test Loss: 0.3165
12.205977767705917

 57%|█████████████████████████████▉                      | 23/40 [01:02<00:45,  2.70s/it, loss_test=0.313]
43.23446995019913
136
Epoch: 22, Training Loss: 0.3179, Test Loss: 0.3130
12.315459787845612

 60%|███████████████████████████████▏                    | 24/40 [01:04<00:42,  2.67s/it, loss_test=0.316]
43.17508840560913
136
Epoch: 23, Training Loss: 0.3175, Test Loss: 0.3158
12.192102581262589

 62%|████████████████████████████████▌                   | 25/40 [01:07<00:39,  2.65s/it, loss_test=0.313]
43.15489837527275
136
Epoch: 24, Training Loss: 0.3173, Test Loss: 0.3126
12.193979799747467

 65%|█████████████████████████████████▊                  | 26/40 [01:10<00:37,  2.68s/it, loss_test=0.313]
43.175275295972824
136
Epoch: 25, Training Loss: 0.3175, Test Loss: 0.3127
12.244595736265182

 68%|███████████████████████████████████                 | 27/40 [01:12<00:34,  2.66s/it, loss_test=0.314]
43.128655314445496
136
Epoch: 26, Training Loss: 0.3171, Test Loss: 0.3140
12.222588628530502
39
43.08810192346573
136
Epoch: 27, Training Loss: 0.3168, Test Loss: 0.3134
12.154401868581772

 70%|████████████████████████████████████▍               | 28/40 [01:15<00:32,  2.68s/it, loss_test=0.313]
43.071238458156586
136
Epoch: 28, Training Loss: 0.3167, Test Loss: 0.3117
12.135731041431427

 72%|█████████████████████████████████████▋              | 29/40 [01:18<00:29,  2.67s/it, loss_test=0.312]
43.05175453424454
136

 75%|███████████████████████████████████████             | 30/40 [01:20<00:26,  2.65s/it, loss_test=0.311]
12.141873002052307
39
43.05923256278038
136
Epoch: 30, Training Loss: 0.3166, Test Loss: 0.3113
12.243197679519653

 78%|████████████████████████████████████████▎           | 31/40 [01:23<00:23,  2.66s/it, loss_test=0.311]
42.94321581721306
136
Epoch: 31, Training Loss: 0.3158, Test Loss: 0.3139
12.153746217489243

 80%|█████████████████████████████████████████▌          | 32/40 [01:26<00:21,  2.64s/it, loss_test=0.314]
42.88200980424881
136
Epoch: 32, Training Loss: 0.3153, Test Loss: 0.3116
12.176321864128113

 82%|██████████████████████████████████████████▉         | 33/40 [01:28<00:18,  2.68s/it, loss_test=0.312]
42.829508036375046
136
Epoch: 33, Training Loss: 0.3149, Test Loss: 0.3122
12.139315754175186

 85%|████████████████████████████████████████████▏       | 34/40 [01:31<00:15,  2.65s/it, loss_test=0.312]
42.87719255685806
136
Epoch: 34, Training Loss: 0.3153, Test Loss: 0.3113
12.1606305539608

 88%|█████████████████████████████████████████████▌      | 35/40 [01:34<00:13,  2.63s/it, loss_test=0.311]
42.86327922344208
136
Epoch: 35, Training Loss: 0.3152, Test Loss: 0.3118
12.260375708341599

 90%|██████████████████████████████████████████████▊     | 36/40 [01:36<00:10,  2.62s/it, loss_test=0.312]
42.809842616319656
136
Epoch: 36, Training Loss: 0.3148, Test Loss: 0.3144
12.187011271715164

 92%|████████████████████████████████████████████████    | 37/40 [01:39<00:07,  2.65s/it, loss_test=0.314]
42.78009212017059
136
Epoch: 37, Training Loss: 0.3146, Test Loss: 0.3125
12.242171555757523

 95%|█████████████████████████████████████████████████▍  | 38/40 [01:42<00:05,  2.67s/it, loss_test=0.312]
42.816146552562714
136

 98%|██████████████████████████████████████████████████▋ | 39/40 [01:44<00:02,  2.69s/it, loss_test=0.314]
12.414604097604752

100%|████████████████████████████████████████████████████| 40/40 [01:47<00:00,  2.69s/it, loss_test=0.318]
42.86302104592323
136
Epoch: 39, Training Loss: 0.3152, Test Loss: 0.3183
Model saved as model_1814138np.pt
Config : {'wandb': True, 'name': 'lstm-enc-dec-6-6-1814138np', 'num_features': 11, 'hidden_size': 256, 'dropout': 0, 'weight_decay': 0, 'input_window': 6, 'output_window': 6, 'learning_rate': 0.0005, 'num_layers': 2, 'num_epochs': 40, 'batch_size': 256, 'train_data_len': 52704, 'training_prediction': 'recursive', 'loss_type': 'RMSE', 'model_label': 'ENC-DEC', 'teacher_forcing_ratio': 0.09999999999999969, 'dynamic_tf': True, 'shuffle': True, 'one_hot_month': False, 'num_of_weigths': 3334, 'num_of_params': 1857291, 'loss_train': [0.4730749474290539, 0.35374226464944725, 0.34296752512454987, 0.3400972939151175, 0.33752013808664155, 0.332850464126643, 0.32753729644943685, 0.3239382698255427, 0.3229082163204165, 0.32286861275925355, 0.32085457400364037, 0.3223818867083858, 0.32147567237124725, 0.31935161571292314, 0.31945670659051223, 0.32009119430885596, 0.3201315880698316, 0.3197746436823817, 0.3192434525665115, 0.31883813068270683, 0.31834009267828045, 0.3180521564448581, 0.31790051433969946, 0.31746388533536124, 0.3173154292299467, 0.31746525952921195, 0.3171224655473934, 0.3168242788490127, 0.3167002827805631, 0.31655701863415103, 0.31661200413809104, 0.31575893983244896, 0.31530889561947656, 0.31492285320864005, 0.3152734746827799, 0.3151711707606035, 0.31477825453176217, 0.3145595008836073, 0.3148246070041376, 0.31516927239649434], 'loss_test': [0.9190514194659698, 0.3332081307203342, 0.3262674541045458, 0.32561426972731566, 0.3244171761549436, 0.323849197381582, 0.31852391820687515, 0.3162284997793344, 0.31453627271529955, 0.3192277390223283, 0.3162174553443224, 0.31389662546989244, 0.3155223872417059, 0.3122501327441289, 0.3120200068522722, 0.3220204397653922, 0.32760531932879716, 0.31780441372822493, 0.3118351445748256, 0.31647794063274676, 0.3124319567130162, 0.3165240371838594, 0.31297378891553634, 0.31578102020116955, 0.31261801490416896, 0.3126661487114735, 0.3139639932375688, 0.31339970842385906, 0.31165132996363515, 0.311172590805934, 0.3113300769757002, 0.3139281456287091, 0.31163451839716005, 0.31221338113149005, 0.31126450651731247, 0.31181103984514874, 0.3143686079061948, 0.312487468505517, 0.3139018347630134, 0.3183231819898654], 'identifier': '1814138np'}