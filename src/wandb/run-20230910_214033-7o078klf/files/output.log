

  2%|█▏                                             | 1/40 [00:17<11:10, 17.19s/it, loss_test=0.907]

  5%|██▎                                            | 2/40 [00:34<10:45, 16.99s/it, loss_test=0.752]
Epoch: 01, Training Loss: 0.7911, Test Loss: 0.7520


 10%|████▋                                          | 4/40 [01:07<10:06, 16.86s/it, loss_test=0.749]
Epoch: 03, Training Loss: 0.7837, Test Loss: 0.7495

 12%|█████▉                                         | 5/40 [01:24<09:50, 16.86s/it, loss_test=0.752]


 18%|████████▏                                      | 7/40 [01:58<09:15, 16.84s/it, loss_test=0.742]
Epoch: 06, Training Loss: 0.7996, Test Loss: 0.7425


 22%|██████████▌                                    | 9/40 [02:31<08:42, 16.86s/it, loss_test=0.754]
Epoch: 08, Training Loss: 0.7896, Test Loss: 0.7540


 28%|████████████▋                                 | 11/40 [03:05<08:06, 16.79s/it, loss_test=0.749]

 30%|█████████████▊                                | 12/40 [03:22<07:50, 16.80s/it, loss_test=0.744]
Epoch: 11, Training Loss: 0.7840, Test Loss: 0.7444


 35%|████████████████                              | 14/40 [03:55<07:17, 16.81s/it, loss_test=0.741]
Epoch: 13, Training Loss: 0.7769, Test Loss: 0.7412


 40%|██████████████████▍                           | 16/40 [04:29<06:44, 16.85s/it, loss_test=0.737]

 42%|███████████████████▌                          | 17/40 [04:46<06:26, 16.80s/it, loss_test=0.741]
Epoch: 16, Training Loss: 0.7696, Test Loss: 0.7413


 48%|█████████████████████▊                        | 19/40 [05:20<05:53, 16.85s/it, loss_test=0.748]
Epoch: 18, Training Loss: 0.7608, Test Loss: 0.7477


 52%|████████████████████████▏                     | 21/40 [05:53<05:20, 16.87s/it, loss_test=0.767]
Epoch: 20, Training Loss: 0.7462, Test Loss: 0.7665


 57%|██████████████████████████▍                   | 23/40 [06:27<04:47, 16.94s/it, loss_test=0.788]

 60%|███████████████████████████▌                  | 24/40 [06:44<04:30, 16.88s/it, loss_test=0.804]
Epoch: 23, Training Loss: 0.7728, Test Loss: 0.8039


 65%|█████████████████████████████▉                | 26/40 [07:18<03:56, 16.87s/it, loss_test=0.755]
Epoch: 25, Training Loss: 0.7779, Test Loss: 0.7553


 70%|████████████████████████████████▏             | 28/40 [07:51<03:22, 16.84s/it, loss_test=0.740]
Epoch: 27, Training Loss: 0.7587, Test Loss: 0.7402

 72%|█████████████████████████████████▎            | 29/40 [08:08<03:05, 16.85s/it, loss_test=0.753]


 78%|███████████████████████████████████▋          | 31/40 [08:42<02:31, 16.85s/it, loss_test=0.749]
Epoch: 30, Training Loss: 0.7466, Test Loss: 0.7495

 80%|████████████████████████████████████▊         | 32/40 [08:59<02:14, 16.85s/it, loss_test=0.755]

 82%|█████████████████████████████████████▉        | 33/40 [09:16<01:58, 16.89s/it, loss_test=0.759]

 85%|███████████████████████████████████████       | 34/40 [09:33<01:41, 16.89s/it, loss_test=0.755]

 88%|████████████████████████████████████████▎     | 35/40 [09:50<01:24, 16.88s/it, loss_test=0.789]

 90%|█████████████████████████████████████████▍    | 36/40 [10:06<01:07, 16.84s/it, loss_test=0.778]

 92%|██████████████████████████████████████████▌   | 37/40 [10:23<00:50, 16.89s/it, loss_test=0.776]


 98%|████████████████████████████████████████████▊ | 39/40 [10:58<00:17, 17.08s/it, loss_test=0.763]

100%|██████████████████████████████████████████████| 40/40 [11:15<00:00, 16.90s/it, loss_test=0.776]
Epoch: 39, Training Loss: 0.7189, Test Loss: 0.7762
Model saved as model_9411715np.pt
Config : {'wandb': True, 'name': 'gru-enc-dec-144-144-9411715np', 'num_features': 11, 'hidden_size': 256, 'dropout': 0, 'weight_decay': 0, 'input_window': 144, 'output_window': 144, 'learning_rate': 0.0005, 'num_layers': 1, 'num_epochs': 40, 'batch_size': 256, 'train_data_len': 52704, 'training_prediction': 'recursive', 'loss_type': 'RMSE', 'model_label': 'ENC-DEC', 'teacher_forcing_ratio': 0.09999999999999969, 'dynamic_tf': True, 'shuffle': True, 'one_hot_month': False, 'num_of_weigths': 74128, 'num_of_params': 604171, 'loss_train': [0.8478832337591383, 0.7911437542350204, 0.7868824481964112, 0.783702474170261, 0.78654502497779, 0.7830167726234153, 0.7996232182891281, 0.7973124155291804, 0.7896371682484945, 0.7878128780259026, 0.7851458130059419, 0.784013338442202, 0.7810070850231029, 0.7768926646974351, 0.7754265520307753, 0.772720013724433, 0.7696490795524032, 0.7657965174427739, 0.7608356396357219, 0.754064436312075, 0.7461940239976954, 0.7367242848431622, 0.7242087576124403, 0.7728108825506987, 0.7871614699010496, 0.7779174049695333, 0.7704523823879383, 0.7586713976330227, 0.7499564347443757, 0.7560636847107499, 0.7466076577151263, 0.7380417223329897, 0.7298623954808271, 0.7234405354217247, 0.7145704680018955, 0.7248170861491451, 0.7058723533595049, 0.7019194806063617, 0.7460685142764338, 0.7188819465813814], 'loss_test': [0.9074368670180037, 0.7520317789670583, 0.7480060248761564, 0.7494796353417474, 0.7521777765170948, 0.7534413031629614, 0.7424568694991034, 0.7840081872166814, 0.7539733583862717, 0.7459849054748947, 0.7492226748853117, 0.7444418588200131, 0.7464915884507669, 0.7412373649107443, 0.7405839932931436, 0.736966152448912, 0.7413471147820756, 0.7469546424375998, 0.7476744522919526, 0.771364772641981, 0.7665464555895006, 0.7750820726961702, 0.7884616239650829, 0.8038519653114112, 0.7612136505745553, 0.7552875763661152, 0.7368111223787874, 0.7402085710216213, 0.753070774916056, 0.7470968881168881, 0.7494709636714008, 0.7551132021723567, 0.7588062608564222, 0.7553763228493768, 0.7885711418615805, 0.7775374844267562, 0.775556514392028, 0.7735789692079699, 0.7630540551366033, 0.7761522547618763], 'identifier': '9411715np'}